# -*- coding: utf-8 -*-
"""gg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18wsk4VkL-RHnou9H0I7FhrUpl4bP95aS
"""

import cv2
from google.colab import drive
import pandas as pd

drive.mount('/content/drive')

pip install opencv-python

import cv2

def extract_frames(video_path, output_dir):
    # Open the video file
    video_capture = cv2.VideoCapture(video_path)

    # Check if the video opened successfully
    if not video_capture.isOpened():
        print("Error: Unable to open video file.")
        return

    # Get some video properties
    fps = video_capture.get(cv2.CAP_PROP_FPS)
    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))

    # Initialize variables
    frame_count = 0
    success = True

    # Loop through the video frames
    while success:
        # Set the frame position to the next second
        video_capture.set(cv2.CAP_PROP_POS_FRAMES, int(fps * frame_count))

        # Read the next frame
        success, frame = video_capture.read()

        # Check if frame was read successfully
        if success:
            # Save the frame to the output directory
            frame_path = f"{output_dir}/frame_{frame_count:05d}.jpg"
            cv2.imwrite(frame_path, frame)
            print(f"Frame {frame_count} saved.")

            # Move to the next second
            frame_count += 1

    # Release the video capture object
    video_capture.release()
    print("Frame extraction completed.")

# Example usage
video_path = "/content/drive/MyDrive/Colab Notebooks/linear.mp4"
output_dir = "/content/drive/MyDrive/Colab Notebooks/Frames2/"
extract_frames(video_path, output_dir)

import os
import cv2
import numpy as np
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.preprocessing.image import img_to_array

# Load MobileNetV2 model without top (fully connected) layers
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Add new top layers for slide classification
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Load pre-trained weights (optional)
# model.load_weights('slide_classification_weights.h5')

# Function to preprocess frame for slide classification
def preprocess_frame(frame):
    resized_frame = cv2.resize(frame, (224, 224))  # Resize frame to input size of the model
    preprocessed_frame = preprocess_input(resized_frame)  # Preprocess frame for the model
    return preprocessed_frame

# Function to classify frame as containing slides or not
def classify_frame(frame):
    preprocessed_frame = preprocess_frame(frame)
    prediction = model.predict(np.expand_dims(preprocessed_frame, axis=0))[0]
    # Assuming binary classification with slide being the positive class
    if prediction > 0.5:
        return True  # Frame contains slides
    else:
        return False  # Frame does not contain slides

# Define input and output directories
input_dir = "/content/drive/MyDrive/Colab Notebooks/Frames2/"
output_dir = "/content/drive/MyDrive/Colab Notebooks/Frames3/"

# Create output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)

# Iterate over frames in input directory
for filename in os.listdir(input_dir):
    if filename.endswith(".jpg") or filename.endswith(".png"):  # Adjust file extensions as needed
        frame_path = os.path.join(input_dir, filename)
        frame = cv2.imread(frame_path)

        if classify_frame(frame):
            output_path = os.path.join(output_dir, filename)
            cv2.imwrite(output_path, frame)

print("Slide classification and saving completed.")

import os
import cv2
import numpy as np
from skimage.metrics import structural_similarity as ssim
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.preprocessing.image import img_to_array

# Load MobileNetV2 model without top (fully connected) layers
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Add new top layers for slide detection
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(4, activation='sigmoid')  # Output 4 coordinates of bounding box (x, y, w, h)
])

# Compile the model
model.compile(optimizer='adam', loss='mse')

# Function to preprocess frame for slide detection
def preprocess_frame(frame):
    resized_frame = cv2.resize(frame, (224, 224))  # Resize frame to input size of the model
    preprocessed_frame = preprocess_input(resized_frame)  # Preprocess frame for the model
    return preprocessed_frame

# Function to detect slides and perform perspective crop
def detect_and_crop_slides(frame):
    # Placeholder function for slide detection and cropping
    # You need to implement object detection for slide detection and perspective crop for each slide region
    return [frame]  # Returning original frame for demonstration

# Define input and output directories
input_dir = "/content/drive/MyDrive/Colab Notebooks/Frames3/"
output_dir = "/content/drive/MyDrive/Colab Notebooks/Frames4/"

# Create output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)

# Initialize variables for temporal feature matching
prev_slide_regions = []

# Set similarity threshold for duplicate removal
threshold = 0.95  # Adjust as needed

# Iterate over frames in input directory
for filename in os.listdir(input_dir):
    if filename.endswith(".jpg") or filename.endswith(".png"):  # Adjust file extensions as needed
        frame_path = os.path.join(input_dir, filename)
        frame = cv2.imread(frame_path)

        # Detect slides and perform perspective crop
        slide_regions = detect_and_crop_slides(frame)

        # Temporal feature matching for clustering and removing duplicates
        unique_slide_regions = []
        for slide_region in slide_regions:
            if any(ssim(cv2.cvtColor(slide_region, cv2.COLOR_BGR2GRAY), cv2.cvtColor(prev_slide_region, cv2.COLOR_BGR2GRAY)) > threshold for prev_slide_region in prev_slide_regions):
                continue
            unique_slide_regions.append(slide_region)

        # Save unique slide regions
        for i, unique_slide_region in enumerate(unique_slide_regions):
            output_path = os.path.join(output_dir, f"{filename}_{i}.jpg")
            cv2.imwrite(output_path, unique_slide_region)

        # Update prev_slide_regions for temporal feature matching
        prev_slide_regions = slide_regions

print("Slide detection, cropping, clustering, and saving completed.")

import os
import cv2
import numpy as np

# Function to find keypoints and descriptors using ORB
def find_keypoints_and_descriptors(image):
    orb = cv2.ORB_create()
    keypoints, descriptors = orb.detectAndCompute(image, None)
    return keypoints, descriptors

# Function to match descriptors between images
def match_descriptors(query_descriptors, train_descriptors):
    matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)
    matches = matcher.match(query_descriptors, train_descriptors)
    return matches

# Function to compute the average distance of matches
def compute_average_distance(matches):
    distances = [match.distance for match in matches]
    if len(distances) > 0:
        return sum(distances) / len(distances)
    else:
        return float('inf')

# Define input directory containing slide images
input_dir = "/content/drive/MyDrive/Colab Notebooks/Frames4/"
# Define output directory for best slide
output_dir = "/content/drive/MyDrive/Colab Notebooks/Frames5/"

# Read the reference image (the first slide)
reference_image = cv2.imread(os.path.join(input_dir, os.listdir(input_dir)[0]), cv2.IMREAD_GRAYSCALE)

# Find keypoints and descriptors for the reference image
reference_keypoints, reference_descriptors = find_keypoints_and_descriptors(reference_image)

# Initialize variables to store best slide information
best_slide_name = None
best_slide_distance = float('inf')

# Iterate over slide images in the input directory (excluding the reference image)
for filename in os.listdir(input_dir)[1:]:
    slide_image = cv2.imread(os.path.join(input_dir, filename), cv2.IMREAD_GRAYSCALE)

    # Find keypoints and descriptors for the current slide image
    slide_keypoints, slide_descriptors = find_keypoints_and_descriptors(slide_image)

    # Match descriptors between reference and slide images
    matches = match_descriptors(reference_descriptors, slide_descriptors)

    # Compute the average distance of matches
    average_distance = compute_average_distance(matches)

    # Update best slide information if the current slide has a lower average distance
    if average_distance < best_slide_distance:
        best_slide_name = filename
        best_slide_distance = average_distance

# Copy the best slide to the output directory
if best_slide_name:
    # Ensure that the output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    # Read the best slide image content
    with open(os.path.join(input_dir, best_slide_name), 'rb') as f:
        slide_content = f.read()
    # Write the best slide image content to the output directory
    with open(os.path.join(output_dir, best_slide_name), 'wb') as f:
        f.write(slide_content)

# Print the best slide information
print("Best Slide Name:", best_slide_name)
print("Best Slide Average Distance:", best_slide_distance)

